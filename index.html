<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jiaqi Liu</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jiaqi Liu
                </p>
                <p> I am a second-year Ph.D. student at the University of Trento, supervised by Prof. <a href="https://disi.unitn.it/~sebe/">Nicu Sebe</a>. My current research interests are in generative models for visual applications.
                </p>
                <p>
                    Before my Ph.D. study, I got both of my master and bachelor degrees from Shanghai Jiao Tong University, majored in automation.
                </p>
                <p style="text-align:center">
                  <a href="mailto:jiaqi.liu@unitn.it">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV_Liujiaqi_202503.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=ePHL_7kAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/jqliu09/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/jiaqiliu_2023.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/jiaqiliu_2023.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <img src='images/cvpr_2025.png' width=100% id="cvpr2025">
          <style type="text/css">
            #cvpr2025{
              position:absolute;
              top:25px;
            }
          </style>
        </div>
        <script type="text/javascript">
          function r2r_start() {
            document.getElementById('r2r_image').style.opacity = "1";
          }

          function r2r_stop() {
            document.getElementById('r2r_image').style.opacity = "0";
          }
          r2r_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2503.15686">
          <span class="papertitle">Multi-focal Conditioned Latent Diffusion for Person Image Synthesis</span>
        </a>
        <br>
        <strong>Jiaqi Liu</strong>, 
        <a href="https://zhangqianhui.github.io/">Jichao Zhang</a>,
        <a href="https://paolorota.eu/">Paolo Rota</a>,
        <a href="https://disi.unitn.it/~sebe/">Nicu Sebe</a>
        <br>
        <em>CVPR</em>, 2025
        <br>
        <a href="https://github.com/jqliu09/MCLD">code</a>
        /
        <a href="https://arxiv.org/abs/2503.15686">arXiv</a>
        <p></p>
        <p>
				Proposes multi-focal condtions to refine the deteriorated sensitive regions for person image synthesis.
        </p>
      </td>
    </tr>

    <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <img src='images/IROS23_2242.png' width=100% id=iros2023>
          <style type="text/css">
            #iros2023{
              position:absolute;
              top:25px;
            }
          </style>
        </div>
        <script type="text/javascript">
          function r2r_start() {
            document.getElementById('r2r_image').style.opacity = "1";
          }

          function r2r_stop() {
            document.getElementById('r2r_image').style.opacity = "0";
          }
          r2r_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2309.00957">
          <span class="papertitle">Visual-Kinematics Graph Learning for Procedure-Agnostic Instrument Tip Segmentation in Robotic Surgeries.</span>
        </a>
        <br>
        <strong>Jiaqi Liu</strong>, 
        <a href="https://scholar.google.com/citations?user=HIjQdFQAAAAJ&hl=zh-CN">Yonghao Long</a>,
        <a href="https://ck-kai.github.io/">Kai Chen</a>,
        Cheuk Hei Leung,
        Zerui Wang,
        <a href="http://www.cse.cuhk.edu.hk/~qdou/">Qi Dou</a>
        <br>
        <em>IROS</em>, 2023
        <br>
        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10342120">paper</a>
        /
        <a href="https://arxiv.org/abs/2309.00957">arXiv</a>
        <p></p>
        <p>
				First work to aggregate kinematic data to improve the procedure-agnostic robotic instrument segmentation by graph learning.
        </p>
      </td>
    </tr>

    <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <img src='images/icra2021.png' width=100% id="icra2021">
          <style type="text/css">
            #icra2021{
              position:absolute;
              top:10px;
            }
          </style>
        </div>
        <script type="text/javascript">
          function r2r_start() {
            document.getElementById('r2r_image').style.opacity = "1";
          }

          function r2r_stop() {
            document.getElementById('r2r_image').style.opacity = "0";
          }
          r2r_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/9562078/">
          <span class="papertitle">Discriminative Asymmetric Learning for Efficient Surgical Instrument Parsing</span>
        </a>
        <br>
        <strong>Jiaqi Liu</strong>, 
        Yu Qiao,
        Jie Yang,
        <a href="https://imr.sjtu.edu.cn/en/po_facultyv/532.html">Guang-zhong Yang</a>,
        <a href="https://imr.sjtu.edu.cn/en/po_facultyv/531.html">Yun Gu</a>,
        <br>
        <em>ICRA</em>, 2021
        <br>
        <a href="https://ieeexplore.ieee.org/document/9562078/">paper</a>
        <p></p>
        <p>
        Discriminative learning in dual-branch network to efficiently parse the details and semantic target in real-time robotic parsing.
        </p>
      </td>
    </tr>

    <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
      <tr>
        <td>
          <h2>Work Experience</h2>
          <ul>
            <li>
                <b>Chinese University of Hong Kong</b>, Hong Kong. 10/2022-7/2023.
                <br/>
                Research Assistant. focusing on kinematic guided robotic parsing.
                <br/>
                Supervisor: <a href="https://www.cse.cuhk.edu.hk/~qdou/" target="_blank">Prof. Qi Dou</a>.
            </li>
                <br/>
            <li>
                  <b>Citic Securities</b>, Shanghai, China. 11/2021-12/2021.
                  <br/>
                  Research Internship, focusing on deep-learning based asset allocation and quantitative investment.
                  <br/>
            </li>
                    <br/>
            <li>
                    <b>Robotic X, Tencent Inc</b>, Shenzhen, China. 04/2021-09/2021.
                    <br/>
                    Research Internship, focusing on grasping pose estimation.
                    <br/>
                    Mentor: <a href="https://ygling2008.github.io/" target="_blank">Dr. Yonggen Ling</a>.
            </li>
           </ul>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Awards</h2>
                <li>Excellent Graduate Award, SJTU, 2022</li>
                <li>National Scholarship, 2021</li>
                <li>Excellent Graduate Award, SJTU, 2019</li>
                <li>Grand Prize, 5th Delta Advanced Automation Contest, 2022</li>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Many thanks to <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a> of the webpage codes.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
